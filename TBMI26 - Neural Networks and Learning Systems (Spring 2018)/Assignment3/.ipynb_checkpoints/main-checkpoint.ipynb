{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBMI26 - Deep Learning Lab ##\n",
    "### Lab overview ###\n",
    "In this lab, you will experience the power of deep learning in an image classification task. The aim is to create a Convolutional Neural Network (CNN) and train it on CIFAR10 dataset.\n",
    "***\n",
    "** CNN **\n",
    "There are hundreds, maybe thousands, of CNN architectures for image classification. In this lab, we will train LeNet [1] on image classification dataset. The architecture of the network is shown below\n",
    "<img src=\"images/lenet.png\" alt=\"Lenet Architecture\" title=\"Lenet Architecture\" />\n",
    "\n",
    "Your <font color=blue>**first task**</font> is to try different combinations of activation functions and subsampling methods. For example:\n",
    "1. Sigmoid activation + average pooling subsampling \n",
    "2. Sigmoid activation + max pooling subsampling \n",
    "3. ReLU activation + average pooling subsampling \n",
    "\n",
    "***\n",
    "\n",
    "The <font color=blue>**second task**</font> is to plot the convergence curves (loss vs. epochs) and (accuracy vs. epochs) and see which of the three combinations above converges faster.\n",
    "\n",
    "***\n",
    "\n",
    "** CIFAR10 **\n",
    "It is one of the earliest datasets for image classification. It has 60,000 images of 10 different classes of images. The dataset is divided into a training set (50,000 images) and a test set (10,000 images)\n",
    "\n",
    "Your <font color=blue>**third task**</font> is to take the last network from the first task and retrain it again using data augmentation (random horizontal flip and random crop). How does this affect the performance of the network ?\n",
    "\n",
    "***\n",
    "\n",
    "The <font color=blue>**final task**</font> is to show some test images with their correpsonding groundtruth and predictions\n",
    "\n",
    "***\n",
    "\n",
    "[1] LeCun, Yann, et al. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE 86.11 (1998): 2278-2324."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from models.Lenet import LeNet\n",
    "from train import *\n",
    "from test import *\n",
    "\n",
    "%matplotlib notebook  \n",
    "\n",
    "# Autoreload modules when they are updated\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Load CIFAR-10 Dataset\n",
    "First, we download and load the CIFAR10 dataset. Pytorch has a built-in function for that. We apply transformations on images in trainin set and test set separately. These transformations are *ToTensor* which normalizes the images to the range from 0 to 1 and then *Normalize* which does contrast normalization for all images to make them zero mean along each channel. Contrast normalization was shown to improve the accuracy of CNNs. More data augmentation trasformations could be added to *transform_train*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if CUDA support is available (GPU)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Image transformations to apply to all images in the dataset (Data Augmentation)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),                # Convert images to Tensors (The data structure that is used by Pytorch)\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # Normalize the images to zero mean\n",
    "])\n",
    "\n",
    "# Image transformations for the test set.\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Specify the path to the CIFAR-10 dataset and create a dataloader where you specify the \"batch_size\"\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# Specify classes labels\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and initialize the network model\n",
    "The network is constructed by creating an object of the class LeNet which defines the network architecture. By default, when this object is created, the weights of each convolution layer are initialized randomly.\n",
    "Afterwards, we define the loss function. We use *CrossEntropyLoss* as it suits multi-label classification tasks. Then we define the training optimizer, you can choose between the famous gradient descent *SGD* or Adam optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sigmoid activation + average pooling subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and initialize the network architecture \n",
    "model1 = LeNet(activation=F.sigmoid, pooling=F.avg_pool2d, pretrained=False)\n",
    "\n",
    "# Load the last save checkpoint\n",
    "use_checkpoint=False\n",
    "\n",
    "if use_cuda:\n",
    "    model1.cuda()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# The objective (loss) function\n",
    "objective = nn.CrossEntropyLoss()\n",
    "\n",
    "# The optimizer used for training the model\n",
    "optimizer = optim.Adam(model1.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_epoch = 1\n",
    "num_epochs = 50\n",
    "model1, loss_log1, acc_log1 = train(model1, trainloader, optimizer, objective, use_cuda, start_epoch, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the network (Run this cell to evaluate on the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc1 = test(model1, testloader, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**What do you observe regarding training and test accuracies?**</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sigmoid activation + max pooling subsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check pytorch documentation for the name of max_pooling layer and modify the function call below to utilize it\n",
    "http://pytorch.org/docs/master/nn.html#pooling-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and initialize the network architecture \n",
    "model2 = LeNet(activation=F.sigmoid, pooling=[], pretrained=False)\n",
    "\n",
    "if use_cuda:\n",
    "    model2.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model2.parameters()) \n",
    "\n",
    "\n",
    "model2, loss_log2, acc_log2 = train(model2, trainloader, optimizer, objective, use_cuda, start_epoch, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc2 = test(model2, testloader, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**How does the max pooling affect the training and test accuracies? and why in your opinion?**</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ReLU activation + average pooling subsampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check pytorch documentation for the name of relu activation function and modify the function call below to utilize it\n",
    "http://pytorch.org/docs/master/nn.html#non-linear-activation-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and initialize the network architecture \n",
    "model3 = LeNet(activation=[], pooling=F.avg_pool2d, pretrained=False)\n",
    "\n",
    "if use_cuda:\n",
    "    model3.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model3.parameters()) \n",
    "\n",
    "\n",
    "model3, loss_log3, acc_log3 = train(model3, trainloader, optimizer, objective, use_cuda, start_epoch, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc3 = test(model3, testloader, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**How does the ReLU activation affect the training and test accuracies? and why in your opinion?**</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot convergence curves\n",
    "Show how the network converges during training by plotting loss vs. epoch and accuracy vs. epoch. A good converging network should have a monotonically decreasing loss and increasing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(range(start_epoch,num_epochs+1), acc_log1, '--b', label='Sig + Avg_pool')\n",
    "plt.plot(range(start_epoch,num_epochs+1), acc_log2, '.m', label='Sig + Max_pool')\n",
    "plt.plot(range(start_epoch,num_epochs+1), acc_log3, 'k', label='ReLU + Avg_pool')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Accuracy (%)')\n",
    "legend = plt.legend()\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(range(start_epoch,num_epochs+1), loss_log1, '--b', label='Sig + Avg_pool')\n",
    "plt.plot(range(start_epoch,num_epochs+1), loss_log2, '.m', label='Sig + Max_pool')\n",
    "plt.plot(range(start_epoch,num_epochs+1), loss_log3, 'k', label='ReLU + Avg_pool')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "legend = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Which network converges faster? and why in you opinion?**</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check torchvision.transforms documentation to see how to perform RandomCrop (to size of 32 x 32 nad padding of 4 pixels) and Random horizontal flip on the input. \n",
    "http://pytorch.org/docs/master/torchvision/transforms.html\n",
    "\n",
    "Add these two transformations instead of the brackets [ ] below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image transformations to apply to all images in the dataset (Data Augmentation)\n",
    "transform_train = transforms.Compose([\n",
    "    [], # Crop all the images randomly to a fixed size\n",
    "    [],    # Randomly flip some of the images horizontaly\n",
    "    transforms.ToTensor(),                # Convert images to Tensors (The data structure that is used by Pytorch)\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # Normalize the images to zero mean\n",
    "])\n",
    "\n",
    "# Specify the path to the CIFAR-10 dataset and create a dataloader where you specify the \"batch_size\"\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to replace the brackets [ ] with the relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and initialize the network architecture \n",
    "model4 = LeNet(activation=[], pooling=F.avg_pool2d, pretrained=False)\n",
    "\n",
    "if use_cuda:\n",
    "    model4.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model4.parameters()) \n",
    "\n",
    "\n",
    "model4, loss_log4, acc_log4 = train(model4, trainloader, optimizer, objective, use_cuda, start_epoch, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc4 = test(model4, testloader, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**How does data augmentation affect the training and test accuracies?**</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = model4(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels.cuda()).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Which class has the lowest accuracy? How do we improve it?**</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some test images with groundtruth and network predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(inp, mean=None, std=None, title=None):          \n",
    "    # Check if input is torch, convert it to numpy\n",
    "    if type(inp) in (torch.cuda.FloatTensor, torch.FloatTensor ):\n",
    "        if inp.shape[0] == 3 :\n",
    "            inp = inp.cpu().numpy().transpose((1, 2, 0))\n",
    "        elif inp.shape[0] == 1 :\n",
    "            inp = np.squeeze(inp.cpu().numpy(), 0)\n",
    "        \n",
    "    if mean is not None and std is not None:\n",
    "        inp = std * inp + mean\n",
    "    plt.imshow(inp.clip(0,1))\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "        \n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(10)))\n",
    "\n",
    "# print images\n",
    "plt.figure()\n",
    "img = torchvision.utils.make_grid(images[0:10], 10)\n",
    "\n",
    "imshow(img, (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "\n",
    "\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Which are the mostly confused classes and why are they confused in your opinion?**</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=Red>Extra Task</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the last network (with data augmentation) three times and plot the convergence curves for the three runs as we did in the second task.\n",
    "Are they identical ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
